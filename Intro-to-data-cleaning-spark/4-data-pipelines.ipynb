{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Import the data to a DataFrame\n",
    "departures_df = spark.read.csv('2015-departures.csv.gz', header=True)\n",
    "\n",
    "# Remove any duration of 0\n",
    "departures_df = departures_df.filter(departures_df[3]>0)\n",
    "\n",
    "# Add an ID column\n",
    "departures_df = departures_df.withColumn('id', F.monotonically_increasing_id())\n",
    "\n",
    "# Write the file out to JSON format\n",
    "departures_df.write.json('output.json', mode='overwrite')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing commented lines\n",
    "\n",
    "```\n",
    "# Import the file to a DataFrame and perform a row count\n",
    "annotations_df = spark.read.csv('annotations.csv.gz', sep='|')\n",
    "full_count = annotations_df.count()\n",
    "\n",
    "# Count the number of rows beginning with '#'\n",
    "comment_count = annotations_df.filter(col('_c0').startswith('#')).count()\n",
    "\n",
    "# Import the file to a new DataFrame, without commented rows\n",
    "no_comments_df = spark.read.csv('annotations.csv.gz', sep='|', comment='#')\n",
    "\n",
    "# Count the new DataFrame and verify the difference is as expected\n",
    "no_comments_count = no_comments_df.count()\n",
    "print(\"Full count: %d\\nComment count: %d\\nRemaining count: %d\" % (full_count, comment_count, no_comments_count))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing invalid rows\n",
    "```\n",
    "# Split _c0 on the tab character and store the list in a variable\n",
    "tmp_fields = F.split(annotations_df['_c0'], '\\t')\n",
    "\n",
    "# Create the colcount column on the DataFrame\n",
    "annotations_df = annotations_df.withColumn('colcount', F.size(tmp_fields))\n",
    "\n",
    "# Remove any rows containing fewer than 5 fields\n",
    "annotations_df_filtered = annotations_df.filter(~ (annotations_df[\"colcount\"] < 5))\n",
    "\n",
    "# Count the number of rows\n",
    "final_count = annotations_df_filtered.count()\n",
    "print(\"Initial count: %d \\nFinal count: %d\" % (initial_count, final_count))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into columns\n",
    "```\n",
    "# Split the content of _c0 on the tab character (aka, '\\t')\n",
    "split_cols = F.split(annotations_df[\"_c0\"], '\\t')\n",
    "\n",
    "# Add the columns folder, filename, width, and height\n",
    "split_df = annotations_df.withColumn('folder', split_cols.getItem(0))\n",
    "split_df = split_df.withColumn('filename', split_cols.getItem(1))\n",
    "split_df = split_df.withColumn('width', split_cols.getItem(2))\n",
    "split_df = split_df.withColumn('height', split_cols.getItem(3))\n",
    "\n",
    "# Add split_cols as a column\n",
    "split_df = split_df.withColumn('split_cols', split_cols)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further parsing\n",
    "\n",
    "```\n",
    "def retriever(cols, colcount):\n",
    "  # Return a list of dog data\n",
    "  return cols[4:colcount]\n",
    "\n",
    "# Define the method as a UDF\n",
    "udfRetriever = F.udf(retriever, ArrayType(StringType()))\n",
    "\n",
    "# Create a new column using your UDF\n",
    "split_df = split_df.withColumn('dog_list', udfRetriever(split_df.split_cols, split_df.colcount))\n",
    "\n",
    "# Remove the original column, split_cols, and the colcount\n",
    "split_df = split_df.drop('_c0').drop('split_cols').drop('colcount')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate rows via join\n",
    "\n",
    "```\n",
    "# Rename the column in valid_folders_df\n",
    "valid_folders_df = valid_folders_df.withColumnRenamed('_c0', 'folder')\n",
    "\n",
    "# Count the number of rows in split_df\n",
    "split_count = split_df.count()\n",
    "\n",
    "# Join the DataFrames\n",
    "joined_df = split_df.join(F.broadcast(valid_folders_df), \"folder\")\n",
    "\n",
    "# Compare the number of rows remaining\n",
    "joined_count = joined_df.count()\n",
    "print(\"Before: %d\\nAfter: %d\" % (split_count, joined_count))\n",
    "```\n",
    "\n",
    "Before: 20580\n",
    "After: 19956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examing invalid rows\n",
    "\n",
    "```\n",
    "# Determine the row counts for each DataFrame\n",
    "split_count = split_df.count()\n",
    "joined_count = joined_df.count()\n",
    "\n",
    "# Create a DataFrame containing the invalid rows\n",
    "invalid_df = split_df.join(F.broadcast(joined_df), 'folder', 'left_anti')\n",
    "\n",
    "# Validate the count of the new DataFrame is as expected\n",
    "invalid_count = invalid_df.count()\n",
    "print(\" split_df:\\t%d\\n joined_df:\\t%d\\n invalid_df: \\t%d\" % (split_count, joined_count, invalid_count))\n",
    "\n",
    "# Determine the number of distinct folder rows removed\n",
    "invalid_folder_count = invalid_df.select('folder').distinct().count()\n",
    "print(\"%d distinct invalid folders found\" % invalid_folder_count)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analysis and delivery\n",
    "\n",
    "# Dog Parsing\n",
    "\n",
    "```\n",
    "# Select the dog details and show 10 untruncated rows\n",
    "print(joined_df.select('dog_list').show(10, truncate=False))\n",
    "\n",
    "# Define a schema type for the details in the dog list\n",
    "DogType = StructType([\n",
    "\tStructField(\"breed\", StringType(), False),\n",
    "    StructField(\"start_x\", IntegerType(), False),\n",
    "    StructField(\"start_y\", StringType(), False),\n",
    "    StructField(\"end_x\", IntegerType(), False),\n",
    "    StructField(\"end_y\", IntegerType(), False),\n",
    "\n",
    "])\n",
    "```\n",
    "\n",
    "# Per image count \n",
    "\n",
    "```\n",
    "# Create a function to return the number and type of dogs as a tuple\n",
    "def dogParse(doglist):\n",
    "  dogs = []\n",
    "  for dog in doglist:\n",
    "    (breed, start_x, start_y, end_x, end_y) = dog.split(',')\n",
    "    dogs.append((breed, int(start_x), int(start_y), int(end_x), int(end_y)))\n",
    "  return dogs\n",
    "\n",
    "# Create a UDF\n",
    "udfDogParse = F.udf(dogParse, ArrayType(DogType))\n",
    "\n",
    "# Use the UDF to list of dogs and drop the old column\n",
    "joined_df = joined_df.withColumn('dogs', udfDogParse('dog_list')).drop('dog_list')\n",
    "\n",
    "# Show the number of dogs in the first 10 rows\n",
    "joined_df.select(F.size('dogs')).show(10)\n",
    "```\n",
    "\n",
    "\n",
    "# Percentage dog pixels\n",
    "```\n",
    "# Define a UDF to determine the number of pixels per image\n",
    "def dogPixelCount(doglist):\n",
    "  totalpixels = 0\n",
    "  for dog in doglist:\n",
    "    totalpixels += (dog[3] - dog[1]) * (dog[4] - dog[2])\n",
    "  return totalpixels\n",
    "\n",
    "# Define a UDF for the pixel count\n",
    "udfDogPixelCount = F.udf(dogPixelCount, IntegerType())\n",
    "joined_df = joined_df.withColumn('dog_pixels', udfDogPixelCount('dogs'))\n",
    "\n",
    "# Create a column representing the percentage of pixels\n",
    "joined_df = joined_df.withColumn('dog_percent', (joined_df.dog_pixels / (joined_df.width * joined_df.height)) * 100)\n",
    "\n",
    "# Show the first 10 annotations with more than 60% dog\n",
    "joined_df.where('dog_percent > 60').show(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
